# Load packages required to define the pipeline:
library(targets)
library(tarchetypes) 
library(tidyverse)
library(tidymodels)
library(stacks)
library(crew)
library(bonsai)
library(lightgbm)

set.seed(12345)

# Set target options:
tar_option_set(packages = c("tidyverse", "tidymodels", "bonsai", "stacks")) 

# Run the R scripts in the R/ folder with your custom functions:
tar_source()

# Define the pipeline:
data_preprocessing <- list(
    
    # Load and preprocess the raw data into wide and long forms
    tar_target(raw_data, "../data/20250211_data.db", format = "file"), # Returns the path to the raw data db file
    tar_target(data_long, readRawCBCsFromDB(raw_data)), # Returns a long-form data frame with anonymized, time-shifted CBC results
    tar_target(data_long_no_zeros, data_long |> filter(RESULT_VALUE_NUMERIC > 0)), # Removes rows where result value is zero
    tar_target(data_wide, pivotCBCData(data_long_no_zeros)), # Returns one row per CBC by patient ID and draw time

    # Calculate priors, posts, and deltas
    tar_target(data_pre_post, calculatePrePost(data_wide)), # Adds prior and subsequent CBC values
    tar_target(data_with_deltas, calculateDeltas(data_pre_post)), # Adds absolute and proportional deltas, with rates of change
    tar_target(data_with_recent_pre_post, data_with_deltas |> filter(hours_since_prior < 48 & hours_to_post < 48)), # Removes any CBCs that don't have recent priors and posts
    tar_target(data_with_rules_based_contamination_flags, applyRulesBasedContaminationFlags(data_with_recent_pre_post)), # Flags CBCs that are likely contaminated
    tar_target(data_quality_check, validateData(data_with_rules_based_contamination_flags)), # Validates the data quality and provides summaries
    
    # Prepare data partitions
    tar_target(training_template, data_with_rules_based_contamination_flags |> filter(DRAWN_DT_TM <= "2024-01-01") |> drop_na()), # Template for training set
    tar_target(WashU_test_set, data_with_rules_based_contamination_flags |> filter(DRAWN_DT_TM >= "2024-01-01") |> drop_na(Hct:Plt_post)), # Test set for model evaluation
    tar_target(WashU_test_metadata, extractTestSetMetadata(raw_data, WashU_test_set)), # Extracts metadata from the test set
    
    # Load Utah Train data
    tar_target(utah_raw_train_data, "../data/utah_cbc_results_2021_2024.tsv", format = "file"), # Returns the path to the Utah data CSV file
    tar_target(utah_train_data_long, read_delim(utah_raw_train_data, delim = "\t")), # Returns a long-form data frame with anonymized, time-shifted CBC results
    
    # Preprocess Utah Test data
    tar_target(utah_train_data_matched_columns, matchUtahColumnsToWashU(utah_train_data_long)), # Removes rows where result value is zero)
    tar_target(utah_train_data_long_no_zeros, utah_train_data_matched_columns |> filter(RESULT_VALUE_NUMERIC > 0)), # Removes rows where result value is zero
    tar_target(utah_train_data_wide, pivotUtahCBCData(utah_train_data_long_no_zeros)), # Returns one row per CBC by patient ID and draw time
    tar_target(utah_train_data_pre_post, calculatePrePost(utah_train_data_wide)), # Adds prior and subsequent CBC values
    tar_target(utah_train_data_with_deltas, calculateDeltas(utah_train_data_pre_post)), # Adds absolute and proportional deltas, with rates of change
    tar_target(utah_train_data_with_recent_pre_post, utah_train_data_with_deltas |> filter(hours_since_prior < 48 & hours_to_post < 48) |> select(-NAME, -AGE, -SEX) |> drop_na()), # Removes any CBCs that don't have recent priors and posts
    tar_target(utah_training_template, applyRulesBasedContaminationFlags(utah_train_data_with_recent_pre_post)), # Flags CBCs that are likely contaminated
    tar_target(utah_train_data_quality_check, validateData(utah_training_template)), # Validates the data quality and provides summaries

    # Load Utah Test data
    tar_target(utah_raw_test_data, "../data/utah_cbc_results_2024_2025.tsv", format = "file"), # Returns the path to the Utah data CSV file
    tar_target(utah_test_data_long, read_delim(utah_raw_test_data, delim = "\t")), # Returns a long-form data frame with anonymized, time-shifted CBC results

    # Preprocess Utah Test data
    tar_target(utah_test_data_matched_columns, matchUtahColumnsToWashU(utah_test_data_long)), # Removes rows where result value is zero)
    tar_target(utah_test_data_long_no_zeros, utah_test_data_matched_columns |> filter(RESULT_VALUE_NUMERIC > 0)), # Removes rows where result value is zero
    tar_target(utah_test_data_wide, pivotUtahCBCData(utah_test_data_long_no_zeros)), # Returns one row per CBC by patient ID and draw time
    tar_target(utah_test_data_pre_post, calculatePrePost(utah_test_data_wide)), # Adds prior and subsequent CBC values
    tar_target(utah_test_data_with_deltas, calculateDeltas(utah_test_data_pre_post)), # Adds absolute and proportional deltas, with rates of change
    tar_target(Utah_test_set, utah_test_data_with_deltas |> filter(hours_since_prior < 48 & hours_to_post < 48) |> drop_na()), # Removes any CBCs that don't have recent priors and posts
    
    tar_target(WashU_transfusion_data_path,"../data/washu_transfusions_data_full_2024.xlsx", format = "file"), # Returns the path to the transfusion data
    tar_target(WashU_transfusion_data, importTransfusionData(WashU_transfusion_data_path)), # Returns a data frame with transfusion data
    tar_target(Utah_transfusion_data_path,"../data/Utah_inpatient_rbc_transfusions_2024_2025.xlsx", format = "file"), # Returns the path to the Utah transfusion data
    tar_target(Utah_transfusion_data, importUtahTransfusionData(Utah_transfusion_data_path)) # Returns a data frame with Utah transfusion data
    
  )

wet_bench_experiment <- list(
  
  
  
)

features = defineFeatures()
training_prevalences = c(0.5)
models = defineModels()

# Build ML inputs 
ml_pipeline <- list(
  
  tar_target(training_templates, list(WashU = training_template, Utah = utah_training_template)),

  tar_map(
    values = expand_grid(training_template = c("WashU", "Utah"), feature_set = names(features), prevalence = training_prevalences, model = c("lgb")),
    
    # Train and Tune Models
    tar_target(training_set, makeSimulatedTrainingSets(training_templates[[training_template]], features[[feature_set]], prevalence)), # Make simulated training sets
    tar_target(rec, recipe(target ~ ., training_set)), # Create the training recipes
    tar_target(wf, workflow(rec, models[[model]])), # Create the ML workflows
    tar_target(wf_tuned, tuneWorkflow(wf)), # Tune the ML workflows to find optimal hyperparameters
    tar_target(wf_fit, fitWorkflow(wf_tuned)), # Fit the ML workflows to the training data
    
    # Evaluate on Cross-Validation
    tar_target(cv_pr_curve_data, getCrossValPrecisionRecall(wf_tuned, prevalence, feature_set, model)), # Data for PR and ROC curves from best performing config in cross-validation
    tar_target(cv_roc_curve_data, getCrossValROC(wf_tuned, prevalence, feature_set, model)), # Data for PR and ROC curves from best performing config in cross-validation
    tar_target(cv_metrics, getCrossValMetrics(wf_tuned, prevalence, feature_set, model)), # Summary of performance metrics for best config on cross-validation
    tar_target(cv_performance_summary, plotCrossValPerformanceSummary(cv_pr_curve_data, cv_roc_curve_data, cv_metrics, label = targets::tar_name())), # Makes summary plot, returns NULL
    tar_target(cv_probability_distributions, getCrossValDistributions(wf_tuned, prevalence, feature_set, model)), # Probability distributions for best config on cross-validation
    
    # Evaluate Models on Held-Out, Un-simulated, Real-World Test Sets
    tar_target(WashU_test_preds, augment(wf_fit |> bundle::unbundle(), WashU_test_set, type = "prob") |> mutate(.pred_class = factor(ifelse(.pred_1 > 0.75, "Contaminated", "Not Contaminated"), levels = c("Not Contaminated", "Contaminated")))), # Class probability estimates on test set with binary predictions at a threshold of 0.1
    #tar_target(WashU_test_preds_with_metadata, addTestMetadata(raw_data, WashU_test_set)), # Adds metadata to predictions for aggregations
    tar_target(Utah_test_preds, augment(wf_fit |> bundle::unbundle(), Utah_test_set, type = "prob") |> mutate(.pred_class = factor(ifelse(.pred_1 > 0.75, "Contaminated", "Not Contaminated"), levels = c("Not Contaminated", "Contaminated")), hg_diff = Hgb_post - Hgb_prior)) # Class probability estimates on test set with binary predictions at a threshold of 0.1

  )
)

ml_stack_pipeline <- list(
  
  tar_target(training_templates, list(WashU = training_template, Utah = utah_training_template)),
  
  tar_map(
    values = expand_grid(training_template = c("WashU", "Utah"), feature_set = c("current_prior_post", "current_prior", "current")),
  
    tar_target(stack_training_set, makeSimulatedTrainingSets(train = training_templates[[training_template]], feature_list_all, prevalence = 0.5)), # Make simulated training sets
    tar_target(wf_set, defineWorkflowSets(stack_training_set, feature_set)), # Create the workflow set
    tar_target(wf_set_tuned, tuneWorkflowSets(wf_set, stack_training_set)), # Tune the workflow set
    tar_target(wf_set_fit, fitBestWorkflows(wf_set_tuned, stack_training_set)), # Fit only the best workflows
    
    tar_target(wf_set_WashU_preds, predictFromWorkflowList(wf_set_fit, WashU_test_set)), # Probability estimates on WashU test set
    tar_target(wf_set_WashU_preds_joined, joinPredsToTransfusions(wf_set_WashU_preds, WashU_transfusion_data)), # Join predictions with transfusion data
    tar_target(wf_set_WashU_transfusions_joined, joinTransfusionsToPreds(wf_set_WashU_preds, WashU_transfusion_data)), # Join transfusion data with predictions
    
    tar_target(wf_set_Utah_preds, predictFromWorkflowList(wf_set_fit, Utah_test_set)), # Probability estimates on Utah test set
    tar_target(wf_set_Utah_preds_joined, joinUtahPredsToTransfusions(wf_set_Utah_preds, Utah_transfusion_data)), # Join predictions with transfusion data
    tar_target(wf_set_Utah_transfusions_joined, joinUtahTransfusionsToPreds(wf_set_Utah_preds, Utah_transfusion_data)) # Join transfusion data with predictions
    #tar_target(stack, stackWorkflowSet(wf_set_tuned)), # Stack workflows into superlearner
    #tar_target(stack_WashU_preds, augment(stack, WashU_test_set, type = "prob", members = T) |> mutate(.pred_class = factor(ifelse(.pred_1 > 0.75, "Contaminated", "Not Contaminated"), levels = c("Not Contaminated", "Contaminated")))), # Probability estimates on WashU test set
    #tar_target(stack_Utah_preds, augment(stack, WashU_test_set, type = "prob", members = T) |> mutate(.pred_class = factor(ifelse(.pred_1 > 0.75, "Contaminated", "Not Contaminated"), levels = c("Not Contaminated", "Contaminated")))) # Probability estimates on Utah test set
    
  )
  
)

# Combine CV Evaluations
#cv_metrics_combined <- tar_combine(cv_metrics_all, ml_pipeline[[4]][["cv_metrics"]], command = bind_rows(!!!.x))
#cv_pr_data_combined <- tar_combine(cv_pr_curve_data_all, ml_pipeline[[4]][["cv_pr_curve_data"]], command = bind_rows(!!!.x))
#cv_roc_data_combined <- tar_combine(cv_roc_curve_data_all, ml_pipeline[[4]][["cv_pr_curve_data"]], command = bind_rows(!!!.x))
#cv_test_preds_combined <- tar_combine(test_preds_all, ml_pipeline[[4]][["test_preds_slim"]], command = bind_rows(!!!.x))

# Make Mix Ratio Regression Models
ml_reg_pipeline <- list(
  
  tar_target(training_reg_templates, list(WashU = training_template, Utah = utah_training_template)),
  
  tar_map(
    values = expand_grid(training_reg_template = c("WashU", "Utah")),
    
  #Make Mix Ratio Regression Models
  tar_target(training_set_reg, makeSimulatedRegressionTrainingSets(training_template, feature_set = features[["prior_post_deltas_only"]])), # Make simulated regression training set
  tar_target(rec_reg, recipe(mix_ratio ~ ., training_set_reg) |> step_pca(all_predictors(), options = list(center = T, scale. = T), keep_original_cols = T)), # Create the regression training recipe
  tar_target(wf_reg, workflow(rec_reg, boost_tree(mode = "regression", trees = 1000, learn_rate = 0.5, loss_reduction = tune(), tree_depth = 12, min_n = tune()) |> set_engine(engine = "lightgbm", nthreads = 1))), # Create the regression workflows
  tar_target(wf_tuned_reg, tuneRegWorkflow(wf_reg)), # Tune the regression workflows to find optimal hyperparameters
  tar_target(wf_fit_reg, fitRegWorkflow(wf_tuned_reg)), # Fit the regression model to the training data
  tar_target(WashU_mix_ratios, augment(wf_fit_reg |> bundle::unbundle(), wf_set_WashU_preds_WashU_current_prior_post)), # Estimate mixture ratios on the test set
  tar_target(Utah_mix_ratios, augment(wf_fit_reg |> bundle::unbundle(), wf_set_Utah_preds_Utah_current_prior_post)) # Estimate mixture ratios on the Utah set
  )
  # Make Mix Ratio Plots
  #tar_target(mix_ratio_scatter, makeMixRatioScatter(test_mix_ratios)) # Makes scatter plot of predicted mixture ratio and contamination probability
  
)

ml_evaluation <- list(
  
  # Import Transfusion Data
  tar_target(WashU_transfusions_joined, joinTransfusionsToPreds(wf_set_WashU_preds_WashU_current_prior_post, WashU_transfusion_data)), # Returns a data frame where each row is a transfusion with the model predictions
  tar_target(WashU_preds_joined, joinPredsToTransfusions(wf_set_WashU_preds_WashU_current_prior_post, WashU_transfusion_data)), # Returns a data frame where each row is a prediction with the transfusion data
  tar_target(WashU_reviewed_all_path, "../data/20250314_WashU_cbc_manual_review_all_1000.xlsx", format = "file"), # Returns the path to the reviewed transfusion data
  tar_target(WashU_reviewed_all, readxl::read_xlsx(WashU_reviewed_all_path)), # Returns a data frame with reviewed transfusion data
  tar_target(WashU_reviewed_transfused_path, "../data/20250316_WashU_transfusions_manual_review.xlsx", format = "file"), # Returns the path to the reviewed transfusion data
  tar_target(WashU_reviewed_transfused, readxl::read_xlsx(WashU_reviewed_transfused_path)), # Returns a data frame with reviewed transfusion data
  
  # Import Utah Transfusion Data
#  tar_target(Utah_transfusion_orders_data_path,"../data/Utah_transfusion_orders_2024_2025.xlsx", format = "file"), # Returns the path to the Utah transfusion data
#  tar_target(Utah_transfusion_orders, importUtahTransfusionOrders(Utah_transfusion_orders_data_path)), # Returns a data frame with Utah transfusion data
  tar_target(Utah_transfusions_joined, joinUtahTransfusionsToPreds(wf_set_Utah_preds_Utah_current_prior_post, Utah_transfusion_data)), # Returns a data frame where each row is a Utah transfusion with the model predictions
  tar_target(Utah_preds_joined, joinUtahPredsToTransfusions(wf_set_Utah_preds_Utah_current_prior_post, Utah_transfusion_data)), # Returns a data frame where each row is a prediction with the Utah transfusion data
  tar_target(Utah_reviewed_all_path, "../data/20250314_Utah_cbc_manual_review_all_1000.xlsx", format = "file"), # Returns the path to the reviewed transfusion data
  tar_target(Utah_reviewed_all, readxl::read_xlsx(Utah_reviewed_all_path), cue = tar_cue("always")), # Returns a data frame with reviewed transfusion data
  tar_target(Utah_reviewed_transfused_path, "../data/20250316_Utah_transfusions_manual_review.xlsx", format = "file"), # Returns the path to the reviewed transfusion data
  tar_target(Utah_reviewed_transfused, readxl::read_xlsx(Utah_reviewed_transfused_path), cue = tar_cue("always")) # Returns a data frame with reviewed transfusion data

  # Make Figures
  #tar_target(transfusion_indication_table, compareTransfusionIndications(WashU_transfusions_joined)), # Makes table comparing transfusion indications
  #tar_target(WashU_transfusion_plots, makeTransfusionPlots(WashU_transfusions_joined, WashU_preds_joined)), # Makes Transfusion-Related Figures, returns NULL
  #tar_target(Utah_transfusion_plots, makeUtahTransfusionPlots(Utah_transfusions_joined, Utah_preds_joined)) # Makes Transfusion-Related Figures, returns NULL
  #tar_target(blood_waste_plots, makeBloodWastePlots(transfusions_joined, preds_joined)) # Makes Blood Waste-Related Figures, returns NULL
  
)

make_figures <- list(
  
  #tar_target(data_summary, makeDataSummaryTable(training_set_WashU_current_prior_post, training_set_Utah_current_prior_post)), # Makes a summary table of the data
  #tar_target(combined_cv_metrics_plot, plotCombinedCrossValSummary(cv_performance_summary_WashU_current_prior_post_with_distance_0.5_lgb, cv_performance_summary_Utah_current_prior_post_with_distance_0.5_lgb)),
  tar_target(combined_pre_post_lines_all_plot, makeCombinedPrePostLines(wf_set_WashU_preds_joined_WashU_current_prior_post, wf_set_Utah_preds_joined_Utah_current_prior_post)),
  #tar_target(transfusion_sankey_plot, makeTransfusionSankey(wf_set_WashU_transfusions_joined_WashU_current_prior_post, wf_set_Utah_preds_joined_Utah_current_prior_post)),
  #tar_target(mix_ratio_combined_plot, makeCombinedMixRatioPlot(WashU_mix_ratios, Utah_mix_ratios)),
  tar_target(contam_rate_by_threshold_plot, makeContaminationRateByThresholdPlot(wf_set_WashU_preds_WashU_current_prior_post, wf_set_Utah_preds_Utah_current_prior_post)),
  tar_target(unnecessary_rate_by_threshold_plot, makeUnnecessaryRateByThresholdPlot(wf_set_WashU_transfusions_joined_WashU_current_prior_post, wf_set_Utah_transfusions_joined_Utah_current_prior_post)),
  tar_target(combined_threshold_plot, ggpubr::ggarrange(contam_rate_by_threshold_plot, unnecessary_rate_by_threshold_plot) %>% ggsave("../figures/final_figures/combined_by_threshold_plot.png", ., width = 12, height = 6, dpi = 600, bg = "white")),
  #tar_target(results_summary_table, makeResultsSummaryTable(wf_set_WashU_preds_WashU_current_prior_post, wf_set_WashU_transfusions_joined_WashU_current_prior_post, WashU_test_metadata, wf_set_Utah_preds_Utah_current_prior_post, wf_set_Utah_transfusions_joined_Utah_current_prior_post)),
  tar_target(hg_diff_plot, makeHgDiffPlot(wf_set_WashU_transfusions_joined_WashU_current_prior_post, wf_set_Utah_transfusions_joined_Utah_current_prior_post))
  #tar_target(explainability_plots, plotExplainability(WashU_transfusions_joined, Utah_transfusions_joined))
  #tar_target(bleeding_summary_plots, makeBleedingSummary(WashU_transfusions_joined, Utah_transfusions_joined))
  
)


# Run the pipeline: 
list(data_preprocessing, 
     #ml_pipeline,
     ml_stack_pipeline,
     #cv_metrics_combined, cv_pr_data_combined, cv_roc_data_combined, cv_test_preds_combined,
     ml_evaluation, 
     ml_reg_pipeline,
     make_figures
     )
